{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition \n",
    "Training and test data are acquired from the [ECMWF's ERA 5 dataset](https://cds.climate.copernicus.eu/datasets/reanalysis-era5-single-levels?tab=download). Because each year's data file is downloaded separately, I did not include them to the repo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import xarray as xr \n",
    "import cfgrib \n",
    "import pandas as pd \n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "from utilities3 import *\n",
    "import time \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Data**  \n",
    "These are the properties of each year's training data \n",
    "* 1216 time steps, 69 latitude, 233 longitude, 15 variables \n",
    "* 31->48 latitude, 0.25 step size \n",
    "* -124->-66 longitude\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10 YEARS OF DATA**  \n",
    "From 2012-2021 with 4 attributes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data conversion  \n",
    "The data is downloaded as .grib file, we first need to convert it to .netcdf, then to CSV file. From CSV we can extract the variables/weather attributes into numpy arrays for fast processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (2012, 2022):\n",
    "    train= xr.open_dataset(f'/home/liuxiang/10yeardata/training/{i}.grib')\n",
    "    train.to_netcdf(f'/home/liuxiang/10yeardata/training/CDF/{i}.nc')\n",
    "    train=xr.open_dataset(f'/home/liuxiang/10yeardata/training/CDF/{i}.nc')\n",
    "    train= train.to_dataframe()\n",
    "    train.to_csv(f'/home/liuxiang/10yeardata/training/CSV/{i}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Test data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2022,2024):\n",
    "    test= xr.open_dataset(f'/home/liuxiang/10yeardata/test/{i}.grib')\n",
    "    test.to_netcdf(f'/home/liuxiang/10yeardata/test/CDF/{i}.nc')\n",
    "    test=xr.open_dataset(f'/home/liuxiang/10yeardata/test/CDF/{i}.nc')\n",
    "    test= test.to_dataframe()\n",
    "    test.to_csv(f'/home/liuxiang/10yeardata/test/CSV/{i}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Process the attributes into variables* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att = ['u10', 'v10', 'train_t2m', 'sp']\n",
    "train_data= np.empty((1464,69,233,4))\n",
    "train_t2m= np.empty((1464,69,233,1))\n",
    "for i in range (2012,2022):\n",
    "    train= pd.read_csv(f'/home/liuxiang/10yeardata/training/CSV/{i}.csv')\n",
    "    u10= train['u10']\n",
    "    v10= train['v10']\n",
    "    t2m= train['t2m']\n",
    "    sp= train['sp']\n",
    "    if i%4==0: \n",
    "        u10= np.resize(u10, (1464,69,233,1))\n",
    "        v10= np.resize(v10, (1464,69,233,1))\n",
    "        t2m= np.resize(t2m, (1464,69,233,1))\n",
    "        sp= np.resize(sp, (1464,69,233,1))\n",
    "        train_i = np.concatenate((u10,v10,t2m,sp), axis=-1)\n",
    "    else: \n",
    "        u10= np.resize(u10, (1460,69,233,1))\n",
    "        v10= np.resize(v10, (1460,69,233,1))\n",
    "        t2m= np.resize(t2m, (1460,69,233,1))\n",
    "        sp= np.resize(sp, (1460,69,233,1))\n",
    "        train_i = np.concatenate((u10,v10,t2m,sp), axis=-1)\n",
    "    print(f'train_i size:{train_i.shape}')\n",
    "    print(f'train_data size:{train_data.shape}')\n",
    "    if i==2012: \n",
    "        train_data[:,:,:,:]= train_i \n",
    "        train_t2m[:,:,:,:]= t2m \n",
    "    else: \n",
    "        train_data= np.concatenate((train_data,train_i), axis=0)\n",
    "        train_t2m= np.concatenate((train_t2m,t2m), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data= np.empty((1460,69,233,4))\n",
    "test_t2m= np.empty((1460,69,233,1))\n",
    "for i in range (2022,2024):\n",
    "    test= pd.read_csv(f'/home/liuxiang/10yeardata/test/CSV/{i}.csv')\n",
    "    u10= test['u10']\n",
    "    v10= test['v10']\n",
    "    t2m= test['t2m']\n",
    "    sp= test['sp']\n",
    "    if i%4==0: \n",
    "        u10= np.resize(u10, (1464,69,233,1))\n",
    "        v10= np.resize(v10, (1464,69,233,1))\n",
    "        t2m= np.resize(t2m, (1464,69,233,1))\n",
    "        sp= np.resize(sp, (1464,69,233,1))\n",
    "        test_i = np.concatenate((u10,v10,t2m,sp), axis=-1)\n",
    "    else: \n",
    "        u10= np.resize(u10, (1460,69,233,1))\n",
    "        v10= np.resize(v10, (1460,69,233,1))\n",
    "        t2m= np.resize(t2m, (1460,69,233,1))\n",
    "        sp= np.resize(sp, (1460,69,233,1))\n",
    "        test_i = np.concatenate((u10,v10,t2m,sp), axis=-1)\n",
    "    if i==2022: \n",
    "        test_data[:,:,:,:]= test_i \n",
    "        test_t2m[:,:,:,:]= t2m \n",
    "    else: \n",
    "        test_data= np.concatenate((test_data,test_i), axis=0)\n",
    "        test_t2m= np.concatenate((test_t2m,t2m), axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
